{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_bayes.ipynb",
      "provenance": [],
      "mount_file_id": "1ValDAiEFTmzNooPKoeaGv3NqTWUpeJFX",
      "authorship_tag": "ABX9TyOuA9UMhI6wzq+Qc+oshnSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackson-gregoire/MachineLearningLearning/blob/main/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "igAEUOMAPjqC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KA5d4KbhMWwY"
      },
      "outputs": [],
      "source": [
        "# All of the data (classes are in the last column -- 101)\n",
        "train = np.loadtxt('/content/drive/MyDrive/data/training_data.txt')\n",
        "test = np.loadtxt('/content/drive/MyDrive/data/testing_data.txt')\n",
        "val = np.loadtxt('/content/drive/MyDrive/data/validation_data.txt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feasture data for training, validation, and testing \n",
        "x_train = train[:,:-1]\n",
        "x_val = val[:,:-1]\n",
        "x_test = test[:,:-1]\n",
        "\n",
        "# Class/target data for training, validation, and testing\n",
        "y_train = train[:,-1]\n",
        "y_val = val[:,-1]\n",
        "y_test = test[:,-1]"
      ],
      "metadata": {
        "id": "G3WljNTga7qI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  More modular fit and predict methods for training and testing.\n",
        "\n",
        "  Note: something weird is going on with the \"training\" for as my decision rule\n",
        "  stands you get 0% training accuracy but when you flip the inequality in the\n",
        "  decision rule you get 100% (meaning I have the classes mixed up? Not sure, they\n",
        "  are labeled oddly). However, the 0% training acc produces a 10% higher testing\n",
        "  accuracy.\n",
        "'''\n",
        "def fit(x_data, labels):\n",
        "  p11, p01, p12, p02  = np.zeros(100), np.zeros(100), np.zeros(100), np.zeros(100)\n",
        "  predictions = [] # Will hold our class predictions\n",
        "  N = len(x_data)\n",
        "\n",
        "  # Estimate the priors\n",
        "  priors = np.array([np.mean(np.where(labels == 1, 1, 0)), \n",
        "                   np.mean(np.where(labels == 2, 1, 0))])\n",
        "  \n",
        "  '''\n",
        "  There's definelty going to be a cleaner way of getting the indv likelihoods\n",
        "  but I'll have to come back to it.\n",
        "  '''\n",
        "  # Get the likelihoods\n",
        "  for x,y in zip(x_data, labels):\n",
        "    for idx, val in enumerate(x):\n",
        "      # Rememeber to normalize by N (the length of X) not by the length of vector\n",
        "      # Also again, this decomposition is fairly uncessary since I add them below\n",
        "      # however, when debugging the original code I needed to write this out for\n",
        "      # clarity.\n",
        "      if y == 1 and val == 1: p11[idx] += 1/N\n",
        "      elif y == 1 and val == 0: p01[idx] += 1/N\n",
        "      elif y == 2 and val == 1: p12[idx] += 1/N\n",
        "      else: p02[idx] += 1/N\n",
        "\n",
        "  p1 = p11 + p01\n",
        "  p2 = p12 + p02\n",
        "\n",
        "  # Calculate the posteriors\n",
        "  for x,y in zip(x_data, labels):\n",
        "    pc1 = np.log(priors[0])\n",
        "    pc2 = np.log(priors[1])\n",
        "\n",
        "    for idx, val in enumerate(x):\n",
        "      if y == 1: pc1 += val*np.log(p1[idx]) + (1-val)*np.log(1-p1[idx])\n",
        "      else: pc2 += val*np.log(p2[idx]) + (1-val)*np.log(1-p2[idx])\n",
        "\n",
        "    print(pc1, pc2)\n",
        "    if pc1 > pc2: predictions.append(1)\n",
        "    else: predictions.append(2)\n",
        "\n",
        "  print(f\"Training Accuracy: {np.mean(np.where(predictions == labels, 1, 0))*100}%\")\n",
        "    \n",
        "  return p1, p2, predictions, priors[0], priors[1]\n",
        "\n",
        "def predict(test_data, test_labels, p1, p2, prior1, prior2):\n",
        "  N = len(test_data)\n",
        "  predictions = []\n",
        "\n",
        "  for x,y in zip(test_data, test_labels):\n",
        "    pc1 = np.log(prior1)\n",
        "    pc2 = np.log(prior2)\n",
        "\n",
        "    for idx, val in enumerate(x):\n",
        "      pc1 += val*np.log(p1[idx]) + (1-val)*np.log(1-p1[idx])\n",
        "      pc2 += val*np.log(p2[idx]) + (1-val)*np.log(1-p2[idx])\n",
        "\n",
        "    if pc1 > pc2: predictions.append(1)\n",
        "    else: predictions.append(2)\n",
        "    print(f\"Prediction: {predictions[-1]}\", f\", Actual: {y}\")\n",
        "\n",
        "  print(f\"Training Accuracy: {np.mean(np.where(predictions == test_labels, 1, 0))*100}%\")"
      ],
      "metadata": {
        "id": "HMH7asuHivCk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1, p2, predictions , prior1, prior2 = fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "XDs3owNVi4mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(x_test, y_test, p1,p2, prior1, prior2)"
      ],
      "metadata": {
        "id": "13mSZxVFlUf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "  --Next--\n",
        "  Finding optimal sigma from validation data using a given prior.\n",
        "\n",
        "'''\n",
        "# Our hyperparameter for validation will be sigma (used in the prior formulation)\n",
        "sigma = np.arange(start = -5, stop = 6)\n",
        "val_acc = []\n",
        "feature_p = 1 - np.mean(x_val, axis = 0)\n",
        "\n",
        "# Finding best sigma on validation set\n",
        "for s in sigma:\n",
        "  priors = np.array([1/(1+np.e**(-s)), 1 - (1/(1+np.e**(-s)))])\n",
        "  predictions = []\n",
        "\n",
        "  for x,y in zip(x_val, y_val):\n",
        "    pc1 = priors[0]\n",
        "    pc2 = priors[1]\n",
        "\n",
        "    for idx, val in enumerate(x):\n",
        "      pc1 *= feature_p[idx]**(1-val)*(1-feature_p[idx])**val + 10**(-10)\n",
        "      pc2 *= (1-feature_p[idx])**(1-val)*(feature_p[idx])**val + 10**(-10)\n",
        "\n",
        "    if pc1 > pc2: predictions.append(1)\n",
        "    else: predictions.append(2)\n",
        "\n",
        "  accuracy = np.mean(np.where(predictions == y_val, 1, 0))\n",
        "  val_acc.append(accuracy)\n",
        "  print(f\"Accuracy for {s}: {accuracy*100}%\")\n",
        "\n",
        "print('-'*50)\n",
        "print(f'Highest validation accuracy: {np.max(val_acc)*100}%')"
      ],
      "metadata": {
        "id": "LiDER5oZs9Di",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  --Old--\n",
        "  None of this is modular, nor takes into account/updates the priors/likelihoods as \n",
        "  new information is introduced.\n",
        "'''\n",
        "\n",
        "priors = np.array([np.mean(np.where(y_train == 1, 1, 0)), \n",
        "                   np.mean(np.where(y_train == 2, 1, 0))])\n",
        "\n",
        "# This will be the occurence of 1, while q hat will represent the lack of, or\n",
        "# presence of 0. p<x input><class>\n",
        "# This was the right idea, but ultimately wasn't doing what I thought it was\n",
        "# as the sum of each classes likelihoods was 1, thus producing nan's when taking\n",
        "# logs.\n",
        "#p11 = np.mean(np.where(x_train[y_train == 1] == 1, 1, 0,), axis = 0) # L(x = 1 | C = 1)\n",
        "#p01 = np.mean(np.where(x_train[y_train == 1] == 0, 1, 0), axis = 0) # L(x = 0 | C = 1)\n",
        "#p12 = np.mean(np.where(x_train[y_train == 2] == 1, 1, 0), axis = 0) # L(x = 1 | C = 2)\n",
        "#p02 = np.mean(np.where(x_train[y_train == 2] == 0, 1, 0), axis = 0) # L(x = 0 | C = 2)\n",
        "\n",
        "p11 = np.zeros(100)\n",
        "p01 = np.zeros(100)\n",
        "p12 = np.zeros(100)\n",
        "p02 = np.zeros(100)\n",
        "\n",
        "for x,y in zip(x_train, y_train):\n",
        "  for idx, val in enumerate(x):\n",
        "    # Rememeber to normalize by N (the length of X) not by the length of vector\n",
        "    if y == 1 and val == 1: p11[idx] += 1/len(x_train) \n",
        "    elif y == 1 and val == 0: p01[idx] += 1/len(x_train)\n",
        "    elif y == 2 and val == 1: p12[idx] += 1/len(x_train)\n",
        "    else: p02[idx] += 1/len(x_train)\n",
        "\n",
        "p1 = p11 + p01\n",
        "p2 = p12 + p02\n",
        "predictions = [] # Will hold our class predictions\n",
        "\n",
        "for x,y in zip(x_train, y_train):\n",
        "  pc1 = np.log(priors[0])\n",
        "  pc2 = np.log(priors[1])\n",
        "\n",
        "  for idx, val in enumerate(x):\n",
        "    if y == 1: pc1 += val*np.log(p1[idx]) + (1-val)*np.log(1-p1[idx])\n",
        "    else: pc2 += val*np.log(p2[idx]) + (1-val)*np.log(1-p2[idx])\n",
        "\n",
        "\n",
        "  if pc1 < pc2: predictions.append(1)\n",
        "  else: predictions.append(2)\n",
        "  #print(f\"Posterior For C = 1: {pc1}\")\n",
        "  #print(f\"Posterior For C = 2: {pc2}\")\n",
        "  print(f'Prediction: {predictions[-1]}')\n",
        "  print(f\"Actual: {y}\")\n",
        "  print('-'*30)\n",
        "\n",
        "print(f\"Accuracy: {np.mean(np.where(predictions == y_train, 1, 0))*100}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9qi5e1YGZG4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  --Old--\n",
        "  Using numerical estimation of priors from the data. This one uses a weird\n",
        "  formulation for Bernoulli, I'm going to rewrite for with more widely published\n",
        "  formulation.\n",
        "'''\n",
        "priors = np.array([np.mean(np.where(y_train == 1, 1, 0)), \n",
        "                   np.mean(np.where(y_train == 2, 1, 0))])\n",
        "\n",
        "# This would only take into account half of the conditional likelihoods I think?\n",
        "feature_p = 1 - np.mean(x_train, axis = 0)\n",
        "predictions = []\n",
        "\n",
        "for x,y in zip(x_train, y_train):\n",
        "  pc1 = priors[0]\n",
        "  pc2 = priors[1]\n",
        "\n",
        "  for idx, val in enumerate(x):\n",
        "    pc1 *= feature_p[idx]**(1-val)*(1-feature_p[idx])**val\n",
        "    pc2 *= (1-feature_p[idx])**(1-val)*(feature_p[idx])**val\n",
        "\n",
        "  if pc1 > pc2: predictions.append(1)\n",
        "  else: predictions.append(2)\n",
        "\n",
        "accuracy = np.mean(np.where(predictions == y_train, 1, 0))\n",
        "print(f\"Accuracy: {accuracy*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWCWvGcFcwoV",
        "outputId": "fd50dd8f-100d-493a-d19a-1138abefab35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.625%\n"
          ]
        }
      ]
    }
  ]
}